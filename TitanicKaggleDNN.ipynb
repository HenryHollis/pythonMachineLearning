{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_418 (Dense)            (None, 60)                1260      \n",
      "_________________________________________________________________\n",
      "dropout_267 (Dropout)        (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_419 (Dense)            (None, 90)                5490      \n",
      "_________________________________________________________________\n",
      "dropout_268 (Dropout)        (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 40)                3640      \n",
      "_________________________________________________________________\n",
      "dropout_269 (Dropout)        (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_421 (Dense)            (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 10,431\n",
      "Trainable params: 10,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      " - 4s - loss: 0.7200 - acc: 0.6139\n",
      "Epoch 2/30\n",
      " - 0s - loss: 0.6276 - acc: 0.6566\n",
      "Epoch 3/30\n",
      " - 0s - loss: 0.5317 - acc: 0.7385\n",
      "Epoch 4/30\n",
      " - 0s - loss: 0.5318 - acc: 0.7755\n",
      "Epoch 5/30\n",
      " - 0s - loss: 0.5232 - acc: 0.7722\n",
      "Epoch 6/30\n",
      " - 0s - loss: 0.4969 - acc: 0.7823\n",
      "Epoch 7/30\n",
      " - 0s - loss: 0.4781 - acc: 0.7868\n",
      "Epoch 8/30\n",
      " - 0s - loss: 0.5150 - acc: 0.7733\n",
      "Epoch 9/30\n",
      " - 0s - loss: 0.4929 - acc: 0.7935\n",
      "Epoch 10/30\n",
      " - 0s - loss: 0.4738 - acc: 0.7868\n",
      "Epoch 11/30\n",
      " - 0s - loss: 0.4960 - acc: 0.7823\n",
      "Epoch 12/30\n",
      " - 0s - loss: 0.4773 - acc: 0.7924\n",
      "Epoch 13/30\n",
      " - 0s - loss: 0.4853 - acc: 0.7946\n",
      "Epoch 14/30\n",
      " - 0s - loss: 0.4627 - acc: 0.7969\n",
      "Epoch 15/30\n",
      " - 0s - loss: 0.4625 - acc: 0.7969\n",
      "Epoch 16/30\n",
      " - 0s - loss: 0.4693 - acc: 0.7912\n",
      "Epoch 17/30\n",
      " - 0s - loss: 0.4805 - acc: 0.8036\n",
      "Epoch 18/30\n",
      " - 0s - loss: 0.4770 - acc: 0.7912\n",
      "Epoch 19/30\n",
      " - 0s - loss: 0.4496 - acc: 0.8103\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.4614 - acc: 0.7912\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.4663 - acc: 0.8036\n",
      "Epoch 22/30\n",
      " - 0s - loss: 0.4988 - acc: 0.8013\n",
      "Epoch 23/30\n",
      " - 0s - loss: 0.4702 - acc: 0.7991\n",
      "Epoch 24/30\n",
      " - 0s - loss: 0.4817 - acc: 0.8013\n",
      "Epoch 25/30\n",
      " - 0s - loss: 0.4573 - acc: 0.8081\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.4653 - acc: 0.8114\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.4609 - acc: 0.7969\n",
      "Epoch 28/30\n",
      " - 0s - loss: 0.4792 - acc: 0.7991\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.4687 - acc: 0.8058\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.4670 - acc: 0.8047\n",
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 1\n",
      " 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 1]\n",
      "[0.11601887 0.67706317 0.10969835 0.10223681 0.69112206 0.0973637\n",
      " 0.8930114  0.32971287 0.864809   0.16768041 0.09640255 0.30258965\n",
      " 0.9372265  0.17665961 0.93465334 0.92945176 0.16241668 0.0944685\n",
      " 0.80957764 0.76641494 0.28172863 0.2238634  0.9389201  0.43130088\n",
      " 0.9025894  0.09902147 0.93626106 0.0944685  0.30258965 0.19824435\n",
      " 0.17494266 0.19855943 0.8604176  0.8346229  0.6204073  0.0944685\n",
      " 0.7154563  0.6968961  0.09474576 0.12104363 0.1001187  0.52547777\n",
      " 0.09159472 0.91543204 0.93465334 0.09380929 0.34255642 0.10374606\n",
      " 0.9378969  0.8112438  0.36444518 0.36323982 0.8905763  0.9019685\n",
      " 0.2322622  0.35871142 0.10162336 0.09380929 0.14852275 0.93510884\n",
      " 0.09683262 0.12211428 0.09683262 0.866365   0.76035684 0.9322515\n",
      " 0.8781358  0.2200456  0.73785895 0.8689147  0.866365   0.09380929\n",
      " 0.8363244  0.73785895 0.9375653  0.6711541  0.09759121 0.92301583\n",
      " 0.12211428 0.866365   0.4519286  0.24858429 0.30258965 0.09640255\n",
      " 0.1276202  0.10751336 0.8930114  0.7442969  0.8962795  0.7117608\n",
      " 0.74974144 0.09640255 0.93134946 0.09759121 0.55509484 0.09380929\n",
      " 0.9359835  0.10162336 0.75535506 0.10223681 0.9356872  0.32498366\n",
      " 0.10374606 0.10162336 0.71915096 0.16130047 0.09998847 0.10374606\n",
      " 0.09759121 0.10452364 0.15575445 0.8689031  0.93510884 0.866365\n",
      " 0.9359835  0.10706241 0.09696108 0.8428627  0.2520858  0.9298838\n",
      " 0.9194816  0.11348996 0.9379803  0.10162336 0.10374606 0.8836824\n",
      " 0.09380929 0.8867683  0.09965504 0.09474576 0.10223681 0.7383175\n",
      " 0.7813768  0.10512166 0.09159472 0.09380929 0.10341255 0.12211428\n",
      " 0.6968961  0.16360234 0.38520962 0.93712133 0.2718537  0.31614742\n",
      " 0.30258965 0.22971995 0.4012791  0.09474576 0.52547777 0.57393247\n",
      " 0.93771124 0.09696108 0.09074239 0.5391151  0.28381404 0.09380929\n",
      " 0.93712133 0.75535506 0.30258965 0.7607073  0.8689031  0.4519286\n",
      " 0.90043384 0.09640255 0.13868076 0.8883499  0.2520858  0.18639696\n",
      " 0.9384987  0.6968961  0.09640255 0.10341255 0.10091    0.09696108\n",
      " 0.16708647 0.91491073 0.92749256 0.28172863 0.8694431  0.93272847\n",
      " 0.12211428 0.29900098 0.93783563 0.10374606 0.93604386 0.14624201\n",
      " 0.9214038  0.12059125 0.30403343 0.09965504 0.32498366 0.52547777\n",
      " 0.23863831 0.10969835 0.59118193 0.10162336 0.8346048  0.7997085\n",
      " 0.10452364 0.78955483 0.91609085 0.25791335 0.6353667  0.8941836\n",
      " 0.10452364 0.58119386 0.8930114  0.10452364 0.9368243  0.09380929\n",
      " 0.16130047 0.09640255 0.17556868 0.91244215 0.30809984 0.2200456\n",
      " 0.8689031  0.264085   0.93076605 0.09759121 0.89220524 0.09474576\n",
      " 0.90362036 0.09380929 0.9361892  0.87542367 0.09380929 0.8689031\n",
      " 0.11057609 0.09965504 0.17556868 0.93602645 0.09899531 0.10374606\n",
      " 0.28172863 0.09380929 0.29896024 0.0944685  0.8307575  0.9356872\n",
      " 0.9361892  0.8936582  0.29900098 0.09640255 0.4465254  0.24169628\n",
      " 0.9318042  0.16946378 0.9298838  0.7743828  0.88596135 0.09380929\n",
      " 0.6204073  0.09474576 0.10223681 0.09640255 0.10374606 0.10223681\n",
      " 0.88039815 0.09380929 0.1265473  0.09380929 0.92251146 0.6015977\n",
      " 0.12815653 0.09640255 0.13546032 0.09640255 0.7154563  0.0973637\n",
      " 0.2520858  0.10374606 0.9379803  0.90594035 0.09696108 0.9214038\n",
      " 0.12211428 0.17494266 0.32498366 0.10452364 0.6968961  0.25791335\n",
      " 0.8689031  0.803391   0.8428627  0.09159472 0.09640255 0.36444518\n",
      " 0.09696108 0.09759121 0.4012791  0.8930114  0.09696108 0.52463216\n",
      " 0.0928615  0.10162336 0.8900518  0.19824435 0.6051371  0.10162336\n",
      " 0.10162336 0.2322622  0.17494266 0.09474576 0.8689031  0.92781895\n",
      " 0.43730417 0.23282269 0.264085   0.6027272  0.0973637  0.0944685\n",
      " 0.09640255 0.7899467  0.9378969  0.8781358  0.28172863 0.10452364\n",
      " 0.10162336 0.19855943 0.10162336 0.0944685  0.12211428 0.69292796\n",
      " 0.9338605  0.09380929 0.8616533  0.2520858  0.32498366 0.10452364\n",
      " 0.90005875 0.34255642 0.09696108 0.87851405 0.10162336 0.69292796\n",
      " 0.12211428 0.11353606 0.15616538 0.26276487 0.10889961 0.10162336\n",
      " 0.16083288 0.9356872  0.25791335 0.7997085  0.12211428 0.76641494\n",
      " 0.10452364 0.9296514  0.9356872  0.10452364 0.17556868 0.1889461\n",
      " 0.7914226  0.30258965 0.9291583  0.09640255 0.10374606 0.9059819\n",
      " 0.20498572 0.9239366  0.93347806 0.10223681 0.93771124 0.34324843\n",
      " 0.10751336 0.8799026  0.9356872  0.12815653 0.11658167 0.9375653\n",
      " 0.11273475 0.09965504 0.9291583  0.93510884 0.5950332  0.10452364\n",
      " 0.2200456  0.28586003 0.10374606 0.11601887 0.78955483 0.8949921\n",
      " 0.10913552 0.8924717  0.09380929 0.09965504 0.09998847 0.36304072\n",
      " 0.37567434 0.93465334 0.5146974  0.09965504 0.23135866 0.93783563\n",
      " 0.09998847 0.93076605 0.09380929 0.11601887 0.93712133 0.17494266\n",
      " 0.93626106 0.4357124  0.36006144 0.1063237  0.11658167 0.29900098\n",
      " 0.8689031  0.6015977  0.8689031  0.93733233 0.8363244  0.09759121\n",
      " 0.9070097  0.09159472 0.09759119 0.5196561 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# list all data in history\\nprint(history.history.keys())\\n\\nplt.plot(history.history['acc'])\\nplt.plot(history.history['val_acc'])\\nplt.title('Model Accuracy')\\nplt.ylabel('Accuracy')\\nplt.xlabel('Epoch')\\nplt.legend(['train', 'test'], loc='upper left')\\nplt.show()\""
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(\"C:/Users/henry/Downloads/all/train.csv\")\n",
    "df_test = pd.read_csv(\"C:/Users/henry/Downloads/all/test.csv\")\n",
    "\n",
    "df_train['Title'] = df_train.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n",
    "df_test['Title'] = df_test.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n",
    "\n",
    "Title_Dictionary = {\n",
    "        \"Capt\":       \"Officer\",\n",
    "        \"Col\":        \"Officer\",\n",
    "        \"Major\":      \"Officer\",\n",
    "        \"Dr\":         \"Officer\",\n",
    "        \"Rev\":        \"Officer\",\n",
    "        \"Jonkheer\":   \"Royalty\",\n",
    "        \"Don\":        \"Royalty\",\n",
    "        \"Sir\" :       \"Royalty\",\n",
    "        \"the Countess\":\"Royalty\",\n",
    "        \"Dona\":       \"Royalty\",\n",
    "        \"Lady\" :      \"Royalty\",\n",
    "        \"Mme\":        \"Mrs\",\n",
    "        \"Ms\":         \"Mrs\",\n",
    "        \"Mrs\" :       \"Mrs\",\n",
    "        \"Mlle\":       \"Miss\",\n",
    "        \"Miss\" :      \"Miss\",\n",
    "        \"Mr\" :        \"Mr\",\n",
    "        \"Master\" :    \"Master\"\n",
    "                   }\n",
    "    \n",
    "# we map each title to correct category\n",
    "df_train['Title'] = df_train.Title.map(Title_Dictionary)\n",
    "df_test['Title'] = df_test.Title.map(Title_Dictionary)\n",
    "age_high_zero_died = df_train[(df_train[\"Age\"] > 0) & \n",
    "                              (df_train[\"Survived\"] == 0)]\n",
    "age_high_zero_surv = df_train[(df_train[\"Age\"] > 0) & \n",
    "                              (df_train[\"Survived\"] == 1)]\n",
    "age_group = df_train.groupby([\"Sex\",\"Pclass\",\"Title\"])[\"Age\"]\n",
    "df_train.loc[df_train.Age.isnull(), 'Age'] = df_train.groupby(['Sex','Pclass','Title']).Age.transform('median')\n",
    "\n",
    "\n",
    "interval = (0, 5, 12, 18, 25, 35, 60, 120)\n",
    "cats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n",
    "\n",
    "df_train[\"Age_cat\"] = pd.cut(df_train.Age, interval, labels=cats)\n",
    "\n",
    "df_train[\"Age_cat\"].head()\n",
    "\n",
    "interval = (0, 5, 12, 18, 25, 35, 60, 120)\n",
    "cats = ['babies', 'Children', 'Teen', 'Student', 'Young', 'Adult', 'Senior']\n",
    "\n",
    "df_test[\"Age_cat\"] = pd.cut(df_test.Age, interval, labels=cats)\n",
    "\n",
    "#Filling the NA's with -0.5\n",
    "df_train.Fare = df_train.Fare.fillna(-0.5)\n",
    "\n",
    "#intervals to categorize\n",
    "quant = (-1, 0, 8, 15, 31, 600)\n",
    "\n",
    "#Labels without input values\n",
    "label_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n",
    "\n",
    "#doing the cut in fare and puting in a new column\n",
    "df_train[\"Fare_cat\"] = pd.cut(df_train.Fare, quant, labels=label_quants)\n",
    "\n",
    "df_test.Fare = df_test.Fare.fillna(-0.5)\n",
    "\n",
    "quant = (-1, 0, 8, 15, 31, 1000)\n",
    "label_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n",
    "\n",
    "df_test[\"Fare_cat\"] = pd.cut(df_test.Fare, quant, labels=label_quants)\n",
    "\n",
    "del df_train[\"Fare\"]\n",
    "del df_train[\"Ticket\"]\n",
    "del df_train[\"Age\"]\n",
    "del df_train[\"Cabin\"]\n",
    "del df_train[\"Name\"]\n",
    "\n",
    "#same in df_test\n",
    "del df_test[\"Fare\"]\n",
    "del df_test[\"Ticket\"]\n",
    "del df_test[\"Age\"]\n",
    "del df_test[\"Cabin\"]\n",
    "del df_test[\"Name\"]\n",
    "df_train[\"Embarked\"] = df_train[\"Embarked\"].fillna('S')\n",
    "\n",
    "\n",
    "df_train[\"FSize\"] = df_train[\"Parch\"] + df_train[\"SibSp\"] + 1\n",
    "\n",
    "df_test[\"FSize\"] = df_test[\"Parch\"] + df_test[\"SibSp\"] + 1\n",
    "\n",
    "del df_train[\"SibSp\"]\n",
    "del df_train[\"Parch\"]\n",
    "\n",
    "del df_test[\"SibSp\"]\n",
    "del df_test[\"Parch\"]\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n",
    "                          prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=[\"Sex\",\"Embarked\",\"Age_cat\",\"Fare_cat\",\"Title\"],\\\n",
    "                         prefix=[\"Sex\",\"Emb\",\"Age\",\"Fare\",\"Prefix\"], drop_first=True)\n",
    "X_train = df_train.drop([\"Survived\",\"PassengerId\"],axis=1)\n",
    "y_train = df_train[\"Survived\"]\n",
    "\n",
    "TestID = df_test[\"PassengerId\"]\n",
    "X_test = df_test.drop([\"PassengerId\"],axis=1)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=60,    \n",
    "        input_dim=20,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=90,    \n",
    "        input_dim=60,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "        units=40,    \n",
    "        input_dim=90,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.50))\n",
    "\n",
    "model.add(keras.layers.Dense(1,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "sgd_optimizer = keras.optimizers.SGD(lr = 0.001, momentum = .99)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd_optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, \n",
    "                    epochs=30, batch_size=10, verbose=2)\n",
    "#scores = model.evaluate(X_train, y_train, batch_size=64)\n",
    "#print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "y_pred = model.predict_classes(X_test, verbose=0)\n",
    "y_pred.resize(418,)\n",
    "\n",
    "#dfOut = pd.DataFrame({\"PassengerId\" : TestID, \"Survived\" : y_pred})\n",
    "#dfOut.to_csv(\"C:/Users/henry/Downloads/all/submission14.csv\", index=False)\n",
    "#print(dfOut)\n",
    "\"\"\"\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
